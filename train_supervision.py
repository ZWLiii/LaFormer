import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping
from tools.cfg import py2cfg
import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"    #è®¾ç½® Hugging Face çš„é•œåƒæœåŠ¡å™¨åœ°å€çš„ç¯å¢ƒå˜é‡
import torch
from torch import nn
import cv2
import numpy as np
import argparse
from pathlib import Path
from tools.metric import Evaluator
from pytorch_lightning.loggers import CSVLogger
import random
import sys
sys.path.append('config/loveda')  #è§£å†³æ‰¾ä¸åˆ°unetformeræ¨¡å—é—®é¢˜


def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

#å…è®¸ç”¨æˆ·åœ¨è¿è¡Œè„šæœ¬æ—¶æŒ‡å®šä¸€ä¸ªé…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
def get_args():
    parser = argparse.ArgumentParser()
    arg = parser.add_argument
    arg("-c", "--config_path", type=Path, help="Path to the config.", required=True)
    return parser.parse_args()

class BinaryEvaluatorWrapper:
    def __init__(self):
        self.evaluator = Evaluator(num_class=2)  # æ˜ç¡®æ˜¯äºŒåˆ†ç±»ï¼ˆ0:èƒŒæ™¯, 1:å‰æ™¯ï¼‰

    def add_batch(self, gt_image, pred_image):
        # ç¡®ä¿è¾“å…¥æ˜¯ 0/1ï¼Œä¸”ç±»å‹æ­£ç¡®
        gt_image = (gt_image > 0).astype(np.uint8)
        pred_image = (pred_image > 0).astype(np.uint8)
        self.evaluator.add_batch(gt_image, pred_image)

    def reset(self):
        self.evaluator.reset()

    def evaluate(self):
        return {
            "IoU": self.evaluator.Intersection_over_Union()[1],
            "F1": self.evaluator.F1()[1],
            "Precision": self.evaluator.Precision()[1],
            "Recall": self.evaluator.Recall()[1]
        }



class Supervision_Train(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.net = config.net
        self.loss = config.loss
        self.use_aux = config.use_aux_loss
        self.num_classes = config.num_classes  # ğŸ‘ˆ å…³é”®ï¼šç”¨äºåˆ¤æ–­ç»“æ„

        self.metrics_train = Evaluator(num_class=2)
        self.metrics_val = Evaluator(num_class=2)

    def forward(self, x):
        return self.net(x)

    def post_process(self, logits):
        """è‡ªåŠ¨æ ¹æ®è¾“å‡ºé€šé“åˆ¤æ–­é¢„æµ‹æ–¹å¼"""
        if logits.shape[1] == 1:
            prob = torch.sigmoid(logits)                   # [B, 1, H, W]
            pred = (prob > 0.5).long().squeeze(1)          # [B, H, W]
        elif logits.shape[1] >= 2:
            prob = torch.softmax(logits, dim=1)            # [B, C, H, W]
            pred = prob.argmax(dim=1).long()               # [B, H, W]
        else:
            raise ValueError(f"Unsupported output shape: {logits.shape}")
        return pred

    def training_step(self, batch, batch_idx):
        img, mask = batch['img'], batch['gt_semantic_seg']
        prediction = self.net(img)
        loss = self.loss(prediction, mask)

        # å–ä¸»è¾“å‡º
        if isinstance(prediction, (tuple, list)) and self.use_aux:
            logits = prediction[0]
        else:
            logits = prediction

        pred_mask = self.post_process(logits)  # ğŸ‘ˆ è‡ªåŠ¨å¤„ç†é¢„æµ‹æ–¹å¼

        for i in range(mask.shape[0]):
            self.metrics_train.add_batch(mask[i].cpu().numpy(), pred_mask[i].cpu().numpy())

        self.log("train_loss", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)
        return {"loss": loss}

    def on_train_epoch_end(self):
        iou = self.metrics_train.Intersection_over_Union()
        f1 = self.metrics_train.F1()[1]
        pre = self.metrics_train.Precision()[1]
        recall = self.metrics_train.Recall()[1]
        oa = self.metrics_train.OA()
        agri_iou = iou[1]
        miou = np.mean(iou)

        self.metrics_train.reset()
        self.log_dict({
            'train_mIoU': miou,
            'train_Agriculture_IoU': agri_iou,
            'train_F1': f1,
            'train_Pre': pre,
            'train_Recall': recall,
            'train_OA': oa
        }, prog_bar=True)

    def validation_step(self, batch, batch_idx):
        img, mask = batch['img'], batch['gt_semantic_seg']
        prediction = self.forward(img)
        loss_val = self.loss(prediction, mask)

        if isinstance(prediction, (tuple, list)) and self.use_aux:
            logits = prediction[0]
        else:
            logits = prediction

        pred_mask = self.post_process(logits)  # ğŸ‘ˆ è‡ªåŠ¨å¤„ç†é¢„æµ‹æ–¹å¼

        for i in range(mask.shape[0]):
            self.metrics_val.add_batch(mask[i].cpu().numpy(), pred_mask[i].cpu().numpy())

        self.log("val_loss", loss_val, on_step=False, on_epoch=True, prog_bar=True, logger=True)
        return {"loss_val": loss_val}

    def on_validation_epoch_end(self):
        iou = self.metrics_val.Intersection_over_Union()
        f1 = self.metrics_val.F1()[1]
        pre = self.metrics_val.Precision()[1]
        recall = self.metrics_val.Recall()[1]
        oa = self.metrics_val.OA()
        agri_iou = iou[1]
        miou = np.mean(iou)

        self.metrics_val.reset()
        self.log_dict({
            'val_mIoU': miou,
            'val_Agriculture_IoU': agri_iou,
            'val_F1': f1,
            'val_Pre': pre,
            'val_Recall': recall,
            'val_OA': oa
        }, prog_bar=True)

    def configure_optimizers(self):
        return [self.config.optimizer], [self.config.lr_scheduler]

    def train_dataloader(self):
        return self.config.train_loader

    def val_dataloader(self):
        return self.config.val_loader


# training
def main():
    args = get_args()       #è·å–å‘½ä»¤è¡Œå‚æ•°
    config = py2cfg(args.config_path)   #è¿™ä¸€æ­¥ä¼šæ‰§è¡Œ odunetformer.py
    seed_everything(42)

    # å®šä¹‰æ—©åœå›è°ƒï¼ˆå…³é”®æ·»åŠ éƒ¨åˆ†ï¼‰
    early_stop = EarlyStopping(
        monitor=config.monitor,  # ç›‘æ§æŒ‡æ ‡ï¼ˆå¦‚ val_mIoUï¼‰
        patience=6,  # è¿ç»­6ä¸ªepochæ— æå‡åˆ™åœæ­¢
        mode=config.monitor_mode,  # æ ¹æ®ç›‘æ§æŒ‡æ ‡æ–¹å‘è®¾ç½®ï¼ˆmax/minï¼‰
        verbose=True  # æ‰“å°æç¤ºä¿¡æ¯
    )

    # é…ç½®æ¨¡å‹ä¿å­˜çš„å›è°ƒå‡½æ•°
    checkpoint_callback = ModelCheckpoint(save_top_k=config.save_top_k, monitor=config.monitor,
                                          save_last=config.save_last, mode=config.monitor_mode,
                                          dirpath=config.weights_path,
                                          filename=config.weights_name)
    # é…ç½®æ—¥å¿—è®°å½•å™¨
    logger = CSVLogger('lightning_logs', name=config.log_name)

    # åˆ›å»ºæ¨¡å‹å¹¶æŒ‡å®šæ¨¡å‹è·¯å¾„ã€æ£€æŸ¥ç‚¹è·¯å¾„ã€æƒé‡åç§°ç­‰å‚æ•°
    model = Supervision_Train(config)

    # å¦‚æœæŒ‡å®šäº†é¢„è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œåˆ™åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹
    if config.pretrained_ckpt_path:
        model = Supervision_Train.load_from_checkpoint(config.pretrained_ckpt_path, config=config)

    # é…ç½® PyTorch Lightning çš„ Trainer
    trainer = pl.Trainer(devices=config.gpus,
                         max_epochs=config.max_epoch,
                         accelerator='auto',
                         check_val_every_n_epoch=config.check_val_every_n_epoch,
                         #val_check_interval=1.0,  # æ¯ä¸ª epoch ç»“æŸåéªŒè¯ä¸€æ¬¡
                         callbacks=[checkpoint_callback, early_stop],
                         strategy='auto',
                         logger=logger)    #è®¾ç½®è®­ç»ƒå™¨

    # å¯åŠ¨è®­ç»ƒ
    trainer.fit(model=model, ckpt_path=config.resume_ckpt_path)


if __name__ == "__main__":
   main()
